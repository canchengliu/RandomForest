#include "header.h"

/* 
 * Split a String by char c
 * return a vector of string
 */

vs split(string& str, char c) {
	vs result;
	string item;
	while (!str.empty() && str.find(c) != string::npos) {
		size_t pos;
		pos = str.find(c);
		item = str.substr(0, pos);
		result.push_back(item);
		str.erase(0, pos + 1);
	}
	result.push_back(item);
	return result;
}

/* 
 * Parses a string and stores data
 * into a vector of vector of strings
 */
void parse(string& someString, vvs &attributeTable){
	vs vectorOfStrings = split(someString, ',');
	attributeTable.push_back(vectorOfStrings);
	vectorOfStrings.clear();
}

/*
 * Prints a vector of vector of strings
 * For debugging purposes only.
 */
void printAttributeTable(vvs &attributeTable){
	int inner, outer;
	for (outer = 0; outer < attributeTable.size(); outer++) {
		for (inner = 0; inner < attributeTable[outer].size(); inner++) {
			cout << attributeTable[outer][inner] << "\t";
		}
		cout << endl;
	}
}

/*
 * Prunes a table based on a column/attribute's name
 * and value of that attribute. Removes that column
 * and all rows that have NOT that value for that column.
 */
vvs pruneTable(vvs &attributeTable, string &colName, string value){
	int i, j;
	vvs prunedTable;
	int column = -1;
	vs headerRow;
	for (i = 0; i < attributeTable[0].size(); i++) {
		if (attributeTable[0][i] == colName) {
			column = i;
			break;
		}
	}
	for (i = 0; i < attributeTable[0].size(); i++) {
		if (i != column) {
		 	headerRow.push_back(attributeTable[0][i]);
		}
	}
	prunedTable.push_back(headerRow);
	for (i = 0; i < attributeTable.size(); i++) {
		vs auxRow;
		if (attributeTable[i][column] == value) {
			for (j = 0; j < attributeTable[i].size(); j++) {
				if(j != column) {
					auxRow.push_back(attributeTable[i][j]);
				}
			}
			prunedTable.push_back(auxRow);
		}
	}
	return prunedTable;
}

/*
 * Recursively builds the decision tree based on
 * the data that it is passed and tha table info.
 */
node* buildDecisionTree(vvs &table, node* nodePtr, vvs &tableInfo){
	if (tableIsEmpty(table)) {
		return NULL;
	}
	if (isHomogeneous(table)) {
		nodePtr->isLeaf = true;
		nodePtr->label = table[1][table[1].size()-1];
		return nodePtr;
	} else {
		string splittingCol = decideSplittingColumn(table);
		nodePtr->splitOn = splittingCol;
		int colIndex = returnColumnIndex(splittingCol, tableInfo);
		int i;
		for (i = 1; i < tableInfo[colIndex].size(); i++) {
			node* newNode = (node*) new node;
			newNode->label = tableInfo[colIndex][i];
			nodePtr->childrenValues.push_back(tableInfo[colIndex][i]);
			newNode->isLeaf = false;
			newNode->splitOn = splittingCol;
			vvs auxTable = pruneTable(table, splittingCol, tableInfo[colIndex][i]);
			nodePtr->children.push_back(buildDecisionTree(auxTable, newNode, tableInfo));
		}
	}
	return nodePtr;
}

/*
 * Returns true if all rows in a subtable
 * have the same class label.
 * This means that that node's class label
 * has been decided.
 */
bool isHomogeneous(vvs &table){
	int i;
	int lastCol = table[0].size() - 1;
	string firstValue = table[1][lastCol];
	for (i = 1; i < table.size(); i++) {
		if (firstValue != table[i][lastCol]) {
			return false;
		}
	}
	return true;
}

/*
 * Returns a vector of integers containing the counts
 * of all the various values of an attribute/column.
 */
vi countDistinct(vvs &table, int column){
	vs vectorOfStrings;
	vi counts;
	bool found = false;
	int foundIndex;
	for (int i = 1; i < table.size(); i++) {
		for (int j = 0; j < vectorOfStrings.size(); j++) {
			if (vectorOfStrings[j] == table[i][column]) {
				found = true;
				foundIndex = j;
				break;
			} else {
				found = false;
			}
		}
		if (!found) {
			counts.push_back(1);
			vectorOfStrings.push_back(table[i][column]);
		} else {
			counts[foundIndex]++;
		}
	}
	int sum = 0;
	for (int i = 0; i < counts.size(); i++) {
		sum += counts[i];
	}
	counts.push_back(table.size());
	return counts;
}

/*
 * Decides which column to split on
 * based on entropy. Returns the column
 * with the least entropy.
 */
string decideSplittingColumn(vvs &table){
	int column, i;
	double minEntropy = DBL_MAX;
	int splittingColumn = 0;
	vi entropies;
	for (column = 0; column < table[0].size() - 1; column++) {
		string colName = table[0][column];
		msi tempMap;
		vi counts = countDistinct(table, column);
		vd attributeEntropy;
		double columnEntropy = 0.0;
		for (i = 1; i < table.size()-1; i++) {
			double entropy = 0.0;
			if (tempMap.find(table[i][column]) != tempMap.end()) { 	// IF ATTRIBUTE IS ALREADY FOUND IN A COLUMN, UPDATE IT'S FREQUENCY
				tempMap[table[i][column]]++;
			} else { 							// IF ATTRIBUTE IS FOUND FOR THE FIRST TIME IN A COLUMN, THEN PROCESS IT AND CALCULATE IT'S ENTROPY
				tempMap[table[i][column]] = 1;
				vvs tempTable = pruneTable(table, colName, table[i][column]);
				vi classCounts = countDistinct(tempTable, tempTable[0].size()-1);
				int j, kkk;
				for (j = 0; j < classCounts.size(); j++) {
					double temp = (double) classCounts[j];
					entropy -= (temp/classCounts[classCounts.size()-1])*(log(temp/classCounts[classCounts.size()-1]) / log(2));
				}
				attributeEntropy.push_back(entropy);
				entropy = 0.0;
			}
		}
		for (i = 0; i < counts.size() - 1; i++) {
			columnEntropy += ((double) counts[i] * (double) attributeEntropy[i]);
		}
		columnEntropy = columnEntropy / ((double) counts[counts.size() - 1]);
		if (columnEntropy <= minEntropy) {
			minEntropy = columnEntropy;
			splittingColumn = column;
		}
	}
	return table[0][splittingColumn];
}

/*
 * Returns an integer which is the
 * index of a column passed as a string
 */
int returnColumnIndex(string &columnName, vvs &tableInfo){
	int i;
	for (i = 0; i < tableInfo.size(); i++) {
		if (tableInfo[i][0] == columnName) {
			return i;
		}
	}
	return -1;
}

/*
 * Returns true if the table is empty
 * returns false otherwise
 */
bool tableIsEmpty(vvs &table){
	return (table.size() == 1);
}

/*
 * Recursively prints the decision tree
 * For debugging purposes only
 */
void printDecisionTree(node* nodePtr){
	if(nodePtr == NULL) {
		return;
	}
	if (!nodePtr->children.empty()) {
		cout << " Value: " << nodePtr->label << endl;
		cout << "Split on: " << nodePtr->splitOn;
		int i;
		for (i = 0; i < nodePtr->children.size(); i++) {   
			cout << "\t";
			printDecisionTree(nodePtr->children[i]);
		}
		return;
        } else {
		cout << "Predicted class = " << nodePtr->label;
		return;
	}
}

/*
 * Takes a row and traverses that row through
 * the decision tree to find out the 
 * predicted class label. If none is found
 * returns the default class label which is
 * the class label with the highest frequency.
 */
string testDataOnDecisionTree(vs &singleLine, node* nodePtr, vvs &tableInfo, string defaultClass){
	string prediction;
	while (!nodePtr->isLeaf && !nodePtr->children.empty()) {
		int index = returnColumnIndex(nodePtr->splitOn, tableInfo);
		string value = singleLine[index];
		int childIndex = returnIndexOfVector(nodePtr->childrenValues, value);
		nodePtr = nodePtr->children[childIndex];
		if (nodePtr == NULL) {
			prediction = defaultClass;
			break;
		}
		prediction = nodePtr->label;
	}
	return prediction;
}

/*
 * Returns an integer which is the index
 * of a string in a vector of strings
 */
int returnIndexOfVector(vs &stringVector, string value){
	int i;
	for (i = 0; i < stringVector.size(); i++) {
		if (stringVector[i] == value)	{
			return i;
		}
	}
	return -1;
}

/*
 * Outputs the predictions to file
 * and returns the accuracy of the classification
 */
double printPredictionsAndCalculateAccuracy(vs &givenData, vs &predictions){
	ofstream outputFile;
	outputFile.open("decisionTreeOutput.txt");
	int correct = 0;
	outputFile << setw(3) << "#" << setw(16) << "Given Class" << setw(31) << right << "Predicted Class" << endl;
	outputFile << "--------------------------------------------------" << endl;
	for (int i = 0; i < givenData.size(); i++) {
		outputFile << setw(3) << i+1 << setw(16) << givenData[i];
		if (givenData[i] == predictions[i]) {
			correct++;
			outputFile << "  ------------  ";
		} else {
			outputFile << "  xxxxxxxxxxxx  ";
		}
		outputFile << predictions[i] << endl;
	}
	outputFile << "--------------------------------------------------" << endl;
	outputFile << "Total number of instances in test data = " << givenData.size() << endl;
	outputFile << "Number of correctly predicted instances = " << correct << endl;
	outputFile.close();
	return (double) correct/50 * 100;
}

/*
 * Returns a vvs which contains information about
 * the data table. The vvs contains the names of
 * all the columns and the values that each
 * column can take
 */
vvs generateTableInfo(vvs &dataTable){
	vvs tableInfo;
	for (int i = 0; i < dataTable[0].size(); i++) {
		vs tempInfo;
		msi tempMap;
		for (int j = 0; j < dataTable.size(); j++) {
			if (tempMap.count(dataTable[j][i]) == 0) {
				tempMap[dataTable[j][i]] = 1;
				tempInfo.push_back(dataTable[j][i]);
			} else	{
				tempMap[dataTable[j][i]]++;
			}
		}
		tableInfo.push_back(tempInfo);
	}
	return tableInfo;
}

/*
 * Returns the most frequent class from the training data
 * This class will be used as the default class label
 */
string returnMostFrequentClass(vvs &dataTable){
	msi trainingClasses;           													 // Stores the classlabels and their frequency
	for (int i = 1; i < dataTable.size(); i++) {
		if (trainingClasses.count(dataTable[i][dataTable[0].size()-1]) == 0) {
			trainingClasses[dataTable[i][dataTable[0].size()-1]] = 1;
		} else {
			trainingClasses[dataTable[i][dataTable[0].size()-1]]++;
		}
	}   
	msi::iterator mapIter;
	int highestClassCount = 0;
	string mostFrequentClass;
	for (mapIter = trainingClasses.begin(); mapIter != trainingClasses.end(); mapIter++) {
		if (mapIter->second >= highestClassCount) {
			highestClassCount = mapIter->second;
			mostFrequentClass = mapIter->first;
		}   
	}
	return mostFrequentClass;
}
